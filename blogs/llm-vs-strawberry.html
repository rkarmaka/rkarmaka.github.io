<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="Ranit Karmakar's personal website" />
    <meta name="keywords" content="Ranit Karmakar, AI, Machine Learning, Medical AI, Bioimage Analysis, Large Language Models, AI Strategy" />
    <meta name="author" content="Ranit Karmakar" />
    <meta name="robots" content="index, follow" />
    <meta name="googlebot" content="index, follow" />
    <meta name="google" content="notranslate" />
    <meta name="google-site-verification" content="your-verification-code" />
    <title>Ranit Karmakar | Portfolio</title>

    

    <!-- Bootstrap 5 CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" />
    <link rel="stylesheet" href="../assets/css/style.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/toolbar/prism-toolbar.min.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.css" />


    <!-- Font -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
  </head>

  <body class="background-level-1">
    <!-- NAVBAR -->
    <nav class="navbar navbar-expand-lg fixed-top border-bottom">
      <div class="container px-4">
        <a class="navbar-brand" href="../index.html">Ranit Karmakar</a>
    
        <!-- Hamburger toggler (no navbar-light/dark needed now) -->
        <button
          class="navbar-toggler"
          type="button"
          data-bs-toggle="collapse"
          data-bs-target="#navbarNav"
          aria-controls="navbarNav"
          aria-expanded="false"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>
    
        <div class="collapse navbar-collapse justify-content-end" id="navbarNav">
          <ul class="navbar-nav align-items-center">
            <li class="nav-item"><a class="nav-link" href="../index.html"><i class="fas fa-house"></i></a></li>
            <li class="nav-item"><a class="nav-link" href="../about.html">My Story</a></li>
            <li class="nav-item"><a class="nav-link" href="../what-i-do.html">What I Do</a></li>
            <li class="nav-item"><a class="nav-link" href="../research.html">Research</a></li>
            <!-- <li class="nav-item"><a class="nav-link" href="projects.html">Projects</a></li> -->
            <li class="nav-item"><a class="nav-link active" href="../blogs.html">Blogs</a></li>
    
            <!-- Theme toggle (icon-only) -->
            <li class="nav-item ms-2">
              <button id="theme-toggle" class="btn-icon" aria-label="Toggle theme">
                <i id="theme-icon" class="fas fa-sun" aria-hidden="true"></i>
              </button>
            </li>
          </ul>
        </div>
      </div>
    </nav>
    

    <!-- MAIN CONTENT -->
    <div class="custom-container main-body">
      <div class="row">
        <!-- PROFILE SECTION -->
        <div class="col-12 col-md-4 col-lg-4 mb-4">
            <div class="level-1 text-center">
              <div class="simple-cover-bg"></div>
              <img src="../assets/images/ranit.png" alt="Profile" class="rounded-circle me-3" />
              <h4 class="mb-1 mt-2">Ranit Karmakar, PhD</h4>
              <p class="text-muted mb-0">
                Researcher | Innovator | Entrepreneur <br />
                <i class="fas fa-briefcase me-2"></i>Harvard University<br />
                <i class="fas fa-map-pin me-2"></i>Boston, MA
              </p>
              <hr/>
              <p>Experienced researcher and builder with a PhD in Medical AI. From scaling automation in industry to leading research and strategy at Harvard, I specialize in applied ML, innovation leadership, and translating research into real-world outcomes.            </p>
              <hr/>
  
              <button class="show-more-btn d-md-none" type="button" data-bs-toggle="collapse" data-bs-target="#moreInfo">
                Show More
              </button>
  
              <div id="moreInfo" class="collapse d-md-block">
                <div class="level-2 text-center mt-4">
                  <h4>Interests</h4>
                  <p>
                    <span class="tag skills">Machine Learning</span>
                    <span class="tag skills">Artificial Intelligence</span>
                    <span class="tag skills">Bioimage Analysis</span>
                    <span class="tag skills">Medical AI</span>
                    <span class="tag skills">Computer Vision</span>
                    <span class="tag skills">Large Language Models</span>
                    <span class="tag skills">AI Strategy</span>
                  </p>
                </div>
                
                <!-- <div class="level-2 text-center mt-4">
                  <h4>Testimonials</h4>
                  <div class="testimonial-slider">
                    <div class="testimonial-card active">
                      <img src="assets/images/ranit.png" alt="Person 1" class="testimonial-img" />
                      <h5>Jane Doe</h5>
                      <p class="designation">AI Lead, HealthTech</p>
                      <p class="testimony">"Ranit’s ability to bridge research and real-world application is simply outstanding."</p>
                    </div>
                    <div class="testimonial-card">
                      <img src="assets/images/ranit.png" alt="Person 2" class="testimonial-img" />
                      <h5>John Smith</h5>
                      <p class="designation">CTO, BioAI Labs</p>
                      <p class="testimony">"Working with Ranit was a masterclass in strategic thinking and innovation."</p>
                    </div>
                    <div class="testimonial-card">
                      <img src="assets/images/ranit.png" alt="Person 3" class="testimonial-img" />
                      <h5>Aisha Ray</h5>
                      <p class="designation">Product Manager, MedML</p>
                      <p class="testimony">"A rare blend of empathy, technical brilliance, and leadership."</p>
                    </div>
                  </div>
                </div> -->
  
                <div class="level-2 text-center mt-4">
                  <h4>Get in Touch</h4>
                  <div class="social-icons">
                    <a href="mailto:your@email.com"><i class="fas fa-envelope"></i></a>
                    <a href="https://github.com/rkarmaka" target="_blank"><i class="fab fa-github"></i></a>
                    <a href="https://www.linkedin.com/in/rkarmaka/" target="_blank"><i class="fab fa-linkedin-in"></i></a>
                    <a href="https://x.com/iRanitK" target="_blank"><i class="fab fa-twitter"></i></a>
                    <a href="https://scholar.google.com/citations?user=gupLB6EAAAAJ&hl=en&oi=ao" target="_blank"><i class="fab fa-google-scholar"></i></a>
                    <a href="https://orcid.org/0000-0003-2427-7920" target="_blank"><i class="fab fa-orcid"></i></a>
                  </div>   
                </div>
              </div>
            </div>
          </div>

        
        <!-- RIGHT COLUMN CONTENT -->
        <div class="col-12 col-md-8 col-lg-8">
            <p><a href="../blogs.html" class="text-decoration-none"><i class="fas fa-arrow-left"></i> Back to Blogs</a></p>
            <article class="level-1 blog-post">
              <header class="mb-4">
                <h1 class="blog-title">Why My LLM Can’t Count the “R”s in <em>Strawberry</em>?</h1>
                <p class="text-muted">Published on April 11, 2025 &middot; <span class="tag skills">AI</span> <span class="tag skills">LLMs</span> <span class="tag skills">Limitations</span> <span class="tag skills">Tokenization</span></p>
              </header>

                <section class="level-2 blog-content mb-4">
                <p><strong>TL;DR</strong>: Your LLM can’t reliably count the <strong>r</strong>’s in <em>strawberry</em> because its entire pipeline—from tokenization to vectorization to attention—optimizes for <strong>meaning over mechanics</strong>. Counting is a symbolic operation that requires character access and an algorithm; standard LLMs have neither by default. Give them character-level visibility or a small tool to do the job, and the problem disappears.</p>
                </section>

                
                <section class="level-2 blog-content mb-4">
                <figure class="blog-image">
                    <img src="../assets/images/blogs/nephew-vs-llm.png" class="img-fluid rounded" alt="Nephew vs LLM">
                    <figcaption>A game my 6-year-old nephew wins against frontier LLMs.</figcaption>
                </figure>
                
                <p>Large language models can explain relativity, crack jokes, help you draft a grant proposal, and even write a haiku about your cat. But then you ask:</p>
          
                <blockquote class="blog-quote">“How many <em>r</em>’s are in <em>strawberry</em>?”</blockquote>
          
                <p>…and suddenly the mighty machine collapses.</p>
          
                <p>This isn’t just funny, it’s deeply revealing. My 6-year-old nephew nails this instantly, yet the same model that can reason about quantum entanglement flubs a 10-letter spelling puzzle. Why? Let’s understand why:</p>
                
                </section>

                <section class="level-2 blog-content mb-4">
                <h2>1. Tokenization Fractures Words Into Chunks</h2>
                <p>Tokenization is how an LLM takes human text and turns it into math. Instead of seeing “s–t–r–a–w–b–e–r–r–y,” the model might see:</p>
                <ul>
                  <li><code>["straw", "berry"]</code></li>
                  <li><code>["st", "raw", "berry"]</code> converting it into numbers like <code>[302, 1618, 19772]</code></li>
                </ul>
                <p>My nephew sees 10 letters. The LLM sees a handful of chunks.</p>
                <p>Here’s the kicker: tokenization is <strong>context-dependent</strong>. The standalone word <em>strawberry</em> might split one way, but in the sentence <em>“How many r’s are in strawberry?”</em> it could be a <strong>single token</strong>. To the model, <em>strawberry</em> might look like just one indivisible <em>token</em>.</p>
                <p>See how ChatGPT tokenizes input using <a href="https://platform.openai.com/tokenizer" target="_blank" class="text-decoration-none">OpenAI Tokenizer <i class="fas fa-external-link-alt"></i></a>.</p>

                
                <figure class="blog-image">
                    <img src="../assets/images/blogs/tokenization.png" class="img-fluid rounded" alt="Tokenization">
                    <figcaption>Tokenization is how an LLM takes human text and turns it into math.</figcaption>
                </figure>



                <h2>2. LLMs are stochastic autoregressors</h2>
                <p>All current chatbots are autoregressors: they predict the next token based on probabilities from training. That means:</p>
                <ul>
                  <li>They don’t “calculate.”</li>
                  <li>They don’t “scan.”</li>
                  <li>They <em>guess the next likely thing</em>.</li>
                </ul>
                <p>Think about it: when was the last time you, or anyone, wrote “<em>strawberry has 3 r’s</em>” on the internet? Basically never. So the model doesn’t have this tucked in memory. Instead, it reaches into its bag of probabilities and blurts out something plausible, like “two” or “four.”</p>
                <p>It’s like asking a poet to do your taxes: they’ll give you something plausible and be confident about it, but you probably shouldn’t file it with the IRS.</p>
                
                <figure class="blog-image">
                    <img src="../assets/images/blogs/poet-doing-taxes.png" class="img-fluid rounded" alt="Poet doing taxes">
                    <figcaption>Asking an LLM to count letters is like asking a poet to do your taxes.</figcaption>
                </figure>
            </section>


                <section class="level-2 blog-content mb-4">
                <h2>How LLMs “See” Text (A Bit Deeper)</h2>
                <ol>
                  <li><strong>Tokens → Vectors</strong><br>
                  Each token becomes a high-dimensional vector that captures distributional properties. These vectors are ideal for meaning, analogy, and context, but <strong>not</strong> for recovering exact character strings.</li>
          
                  <li><strong>Attention runs over tokens, not letters</strong><br>
                  Self-attention relates tokens to other tokens. Positional encodings tell the model where tokens sit, but positions refer to tokens—not characters.</li>
          
                  <li><strong>Why “just learn counting” is hard</strong><br>
                  Counting requires a discrete, stepwise algorithm (scan → accumulate → compare). Transformers <em>can</em> emulate such routines with supervision, but it’s brittle.</li>
                </ol>
                <hr />

                <h2>How to Get the Right Answer (Reliable Workarounds)</h2>
                <h3>1) Force character-level visibility in the prompt</h3>
                <ul>
                  <li><strong>Space out the letters:</strong> “Count the ‘r’s in <code>s t r a w b e r r y</code>.”</li>
                  <li><strong>Use separators:</strong> “Count the ‘r’s in <code>s|t|r|a|w|b|e|r|r|y</code>.”</li>
                </ul>
          
                <h3>2) Ask the model to <strong>spell first, then count</strong></h3>
                <ol>
                  <li>“Spell <em>strawberry</em> with spaces between each letter.”</li>
                  <li>“Now count the number of ‘r’ characters you just wrote.”</li>
                </ol>
          
                <h3>3) Use a tool for deterministic counting</h3>
                <pre class="blog-code"><code class="language-python">word = "strawberry"
sum(c.lower() == "r" for c in word)</code></pre>
          
                <h3>4) Finetune or choose character-aware models</h3>
                <p>If letter-precise tasks are central, use character/byte-level tokenization or finetune on character-level objectives. Still, deterministic fallbacks are best.</p>
                </section>

                <section class="level-2 blog-content mb-4">
                <h2>Quick Reference: Prompt Patterns That Work</h2>
                <ul>
                  <li><strong>Simple spacing:</strong> “Write <em>strawberry</em> as individual letters separated by spaces, then count the number of ‘r’s.”</li>
                  <li><strong>Verification step:</strong> “Show the letters you are counting, then give the count as a final number.”</li>
                  <li><strong>Constrained output:</strong> “Return JSON with fields <code>letters</code> (array of characters) and <code>count_r</code> (integer).”</li>
                </ul>
                
                <hr />

                <h2>Practical Takeaways</h2>
                <ul>
                  <li><strong>Expectation setting:</strong> LLMs are phenomenal semantic engines, not symbol counters.</li>
                  <li><strong>Design principle:</strong> When you need <em>exactness</em>, offload to a tool or force character-level view.</li>
                  <li><strong>Robustness over cleverness:</strong> A one-line helper function is more reliable than prompt wizardry.</li>
                </ul>
                </section>

                <section class="level-2 blog-content mb-4">
                <h2>Final Word</h2>
                <p>The <em>strawberry</em> test is funny, but it’s also profound. It reminds us that LLMs are <strong>masters of meaning</strong>, not mechanics. They’ll wax lyrical about strawberries and their antioxidant properties, but ask them to count r’s and you’ve got a confused poet fumbling with a spelling quiz.</p>
                <p>So when precision matters? Don’t leave it to the poet. Hand them a calculator. Or better yet, let your six-year-old nephew check the spelling. He won’t miss.</p>
              </section>
            </article>
          </div>
          
  

  
      </div>
    </div>

    <!-- FOOTER -->
    <hr />
    <footer class="text-center">
      <p>&copy; 2024 Ranit Karmakar</p>
    </footer>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="../assets/js/script.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/toolbar/prism-toolbar.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.js"></script>
  </body>
</html>